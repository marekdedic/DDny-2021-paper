\section{Introduction}

\todo{R1: It is very difficult to understand the concrete goal of the paper. It is important to describe the added value of the proposed framework comparing with the existing HARP method.}
\todo{R1: What is the motivation behind using partially injective homomorphism instead of existing coarsening techniques of HARP? is it simpler to compute? does it improve the learning performance? it is important that the paper provides a clear answer to this question, as this point is one of its main contributions.}
\todo{Section 3 presents partially injective homomorphisms. Before reaching this section, the paper does not provide the reason why this concept is important to present. This needs to be explained at least in the introduction.}
Graph-based models for machine learning are often used for task with millions of nodes and billions of edges. For such tasks, many machine learning algorithms may be computationally intractable. As a way to combat these growing demands, we look at the trade-off between performance, complexity and method generality. Our work in progress builds on HARP \cite{chen_harp_2018} and proposes a general framework for coarsening graphs and examines the performance characteristics of models trained on these coarser graphs.

In the next section, the graph learning algorithm HARP is presented, followed by a section presenting partially injective homomorphisms. Section \ref{sec:harp-as-pihom} connects these ideas and Section \ref{sec:performance-vs-complexity} discusses the performance characteristics of HARP. Finally, Section \ref{sec:experiments} supports our theses with experimental evaluation.
